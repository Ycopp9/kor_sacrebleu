{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79b294e4-71aa-46ae-b0e3-5ce10ca221f1",
   "metadata": {},
   "source": [
    "### option 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fbc1fbb-e394-409b-bd3d-81fa0bf34a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bash: tokenizer.sh: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "#input filename, format\n",
    "!bash tokenizer.sh sample tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dfe8b7-a374-456b-8b94-4e2f394277df",
   "metadata": {},
   "source": [
    "### option 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f435aac9-5522-460d-871f-f4d38901f79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE=$1\n",
    "format=$2\n",
    "\n",
    "python preprocessor.py \\\n",
    "    --input=$FILE.$format \\\n",
    "    #--spm=spm/spm.ko.model \\\n",
    "    --spm=tool/tokenizer/spm.ko.model \\\n",
    "    --tsv \\\n",
    "    --preprocessing='Kkma Hannanum Okt Komoran Mecab Khaiii Kiwi Spm Syllable CV' \\\n",
    "    Ref Hyp\n",
    "\n",
    "mkdir -p result\n",
    "python csv2txt.py \\\n",
    "    --input=$FILE.ppc.$format \\\n",
    "    --tsv \\\n",
    "    Kkma Hannanum Okt Komoran Mecab Khaiii Kiwi Spm Syllable CV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d841730-697a-486b-9a50-687247623508",
   "metadata": {},
   "source": [
    "### option 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc577164-3bb9-4948-ba18-fd567ef41541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/private/_git/kor_sacre\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1331f2a5-00dd-47b2-a543-86e5fb5d1cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!FILE=sample\n",
    "!format=tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1aac8c86-2104-4ef1-bcb0-34d254af6114",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"preprocessor.py\", line 135, in <module>\n",
      "    main()\n",
      "  File \"preprocessor.py\", line 107, in main\n",
      "    df = pd.read_csv(args.input)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\", line 688, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\", line 454, in _read\n",
      "    parser = TextFileReader(fp_or_buf, **kwds)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\", line 948, in __init__\n",
      "    self._make_engine(self.engine)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\", line 1180, in _make_engine\n",
      "    self._engine = CParserWrapper(self.f, **self.options)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\", line 2010, in __init__\n",
      "    self._reader = parsers.TextReader(src, **kwds)\n",
      "  File \"pandas/_libs/parsers.pyx\", line 537, in pandas._libs.parsers.TextReader.__cinit__\n",
      "  File \"pandas/_libs/parsers.pyx\", line 711, in pandas._libs.parsers.TextReader._get_header\n",
      "  File \"pandas/_libs/parsers.pyx\", line 905, in pandas._libs.parsers.TextReader._tokenize_rows\n",
      "  File \"pandas/_libs/parsers.pyx\", line 2042, in pandas._libs.parsers.raise_parser_error\n",
      "pandas.errors.ParserError: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.\n"
     ]
    }
   ],
   "source": [
    "!python preprocessor.py \\\n",
    "    --input=$FILE.$format \\\n",
    "    #--spm=spm/spm.ko.model \\\n",
    "    --spm=tool/tokenizer/spm.ko.model \\\n",
    "    --tsv \\\n",
    "    --preprocessing='Kkma Hannanum Okt Komoran Mecab Khaiii Kiwi Spm Syllable CV' \\\n",
    "    Ref Hyp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a424ab-983b-4563-b734-8c934805f293",
   "metadata": {},
   "source": [
    "### option 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c11ced38-86fc-4144-b497-d5525fc2c189",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing ['CV', 'Syllable', 'Hannanum', 'Kiwi', 'Kkma', 'Okt', 'Spm', 'Khaiii', 'Komoran', 'Mecab']\n",
      "Ref CV completed\n",
      "time : 0.0006546974182128906\n",
      "Hyp CV completed\n",
      "time : 0.0005707740783691406\n",
      "Ref Syllable completed\n",
      "time : 0.0004444122314453125\n",
      "Hyp Syllable completed\n",
      "time : 0.00042819976806640625\n",
      "Ref Hannanum completed\n",
      "time : 0.40392422676086426\n",
      "Hyp Hannanum completed\n",
      "time : 0.008960247039794922\n",
      "Ref Kiwi completed\n",
      "time : 0.25903892517089844\n",
      "Hyp Kiwi completed\n",
      "time : 0.0023565292358398438\n",
      "Ref Kkma completed\n",
      "time : 7.418205738067627\n",
      "Hyp Kkma completed\n",
      "time : 0.030872344970703125\n",
      "Ref Okt completed\n",
      "time : 4.195801734924316\n",
      "Hyp Okt completed\n",
      "time : 0.048987388610839844\n",
      "Ref Spm completed\n",
      "time : 0.0015549659729003906\n",
      "Hyp Spm completed\n",
      "time : 0.0008242130279541016\n",
      "Ref Khaiii completed\n",
      "time : 0.0028204917907714844\n",
      "Hyp Khaiii completed\n",
      "time : 0.001979351043701172\n",
      "Ref Komoran completed\n",
      "time : 0.016112089157104492\n",
      "Hyp Komoran completed\n",
      "time : 0.007867813110351562\n",
      "Ref Mecab completed\n",
      "time : 0.001971006393432617\n",
      "Hyp Mecab completed\n",
      "time : 0.000988006591796875\n",
      "Traceback (most recent call last):\n",
      "  File \"tool/csv2txt.py\", line 40, in <module>\n",
      "    main()\n",
      "  File \"tool/csv2txt.py\", line 31, in main\n",
      "    f.writelines([data+'\\n' for data in df[\"{0}_{1}\".format(column, ppc)].values.tolist()])\n",
      "UnicodeEncodeError: 'ascii' codec can't encode characters in position 0-1: ordinal not in range(128)\n"
     ]
    }
   ],
   "source": [
    "!bash tool/tokenizer.sh data/sample tsv \"Ref Hyp\" \"Kkma Hannanum Okt Komoran Mecab Khaiii Kiwi Spm Syllable CV\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e71669a-c04e-4c90-8c77-3d9c16d1cee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/private/_git/kor_sacre\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f944be-a049-415a-af7c-4c4f39f7d965",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
